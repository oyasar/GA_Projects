{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Capstone Project Part 2 </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Web Scraping with Beautiful Soup </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from queue import Queue\n",
    "import time\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "from multiprocessing.dummy import Pool  # This is a thread-based Pool\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_summary import DataFrameSummary\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# prod_page_link = soup.find('a', {'class':'prodItemThumb_link'})['href']\n",
    "# prod_title = soup.find('span', {'class': 'prodItemInfo_name'})['title']\n",
    "# prod_variety = soup.find('span', {'class': 'prodItemInfo_varietal'}).text\n",
    "# prod_origin = soup.find('span', {'class': 'prodItemInfo_originText'}).text\n",
    "# prod_ratings = soup.find('span', {'class': 'averageRating_average'}).text\n",
    "# prod_rating_average = soup.find('span', {'class': 'averageRating_average'}).text\n",
    "# prod_price = soup.find('span', {'class': 'productPrice_price-regWhole'}).text\n",
    "# prod_type = soup.find('li', {'class': 'icon icon-glass-red prodAttr_icon prodAttr_icon-redWine'})['title']\n",
    "\n",
    "\n",
    "# prod_img_link = soup.find('img', {'class': 'prodItemThumb_image'})['src']\n",
    "\n",
    "# pprint(prod_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product name\n",
    "def prod_title(soup):\n",
    "    l = []\n",
    "    for item in soup.find_all('span', {'class': 'prodItemInfo_name'}):\n",
    "        try:\n",
    "            prod_title = item.text\n",
    "        except:\n",
    "            prod_title = None\n",
    "        l.append(prod_title)\n",
    "    return l\n",
    "\n",
    "# product page link for further information and comments\n",
    "def prodpage_link(soup):\n",
    "    l=[]\n",
    "    for item in soup.find_all('a', {'class':'prodItemThumb_link'}):\n",
    "        try:\n",
    "            prod_page_link = item['href']\n",
    "        except:\n",
    "            prod_page_link = None\n",
    "        l.append(prod_page_link)\n",
    "    return l\n",
    "\n",
    "# product variety\n",
    "def prod_variety(soup):\n",
    "    l = []\n",
    "    for item in soup.find_all('span', {'class': 'prodItemInfo_varietal'}):\n",
    "        try:\n",
    "            prod_variety = item.text\n",
    "        except:\n",
    "            prod_variety = None\n",
    "        l.append(prod_variety)\n",
    "    return l\n",
    "\n",
    "# product origin\n",
    "\n",
    "def prod_origin(soup):\n",
    "    l = []\n",
    "    for item in soup.find_all('span', {'class': 'prodItemInfo_originText'}):\n",
    "        try:\n",
    "            prod_origin = item.text\n",
    "        except:\n",
    "            prod_origin = None\n",
    "        l.append(prod_origin)\n",
    "    return l\n",
    "\n",
    "# prod site rating\n",
    "def prod_site_rating_count(soup):\n",
    "    l = []\n",
    "    for item in soup.find_all('span', {'class': 'averageRating_count'}):\n",
    "        try:\n",
    "            prod_ratings = item.text.strip('Ratings')\n",
    "        except:\n",
    "            prod_ratings = None\n",
    "        l.append(prod_ratings)\n",
    "    return l\n",
    "\n",
    "# prod site rating average\n",
    "def prod_site_rateaverage(soup):\n",
    "    l = []\n",
    "    for item in soup.find_all('span', {'class': 'averageRating_average'}):\n",
    "        try:\n",
    "            prod_rating_average = item.text\n",
    "        except:\n",
    "            prod_rating_average = None\n",
    "        l.append(prod_rating_average)\n",
    "    return l\n",
    "\n",
    "# prod price\n",
    "\n",
    "def prod_price(soup):\n",
    "    l = []\n",
    "    for item in soup.find_all('span', {'class': 'productPrice_price-regWhole'}):\n",
    "        try:\n",
    "            prod_price = item.text\n",
    "        except:\n",
    "            prod_price = None\n",
    "        l.append(prod_price)\n",
    "    return l\n",
    "\n",
    "        \n",
    "# get image\n",
    "def get_img(soup):\n",
    "    l = []\n",
    "    a = soup.find_all('img', {'class': 'prodItemThumb_image'})\n",
    "    b = prod_title(soup)\n",
    "    for img, title in zip(a, b):\n",
    "\n",
    "        try:\n",
    "            prod_img_link = img['src']\n",
    "        except:\n",
    "            prod_img_link = None\n",
    "\n",
    "        img_url = 'http://www.wine.com{}'.format(prod_img_link)\n",
    "        dir_name = 'images'\n",
    "        file_name = dir_name + '/{}.jpg'.format(title.replace(\" \", '_').replace('/', '_')) \n",
    "        urlretrieve(img_url, file_name)\n",
    "        l.append(img_url)\n",
    "    return l\n",
    "\n",
    "def other_rate(soup):\n",
    "    l = []\n",
    "    m = []\n",
    "    uls = soup.find_all('ul', {'class': 'wineRatings_list'})\n",
    "\n",
    "    for ul in uls:\n",
    "        title = []\n",
    "        review = []\n",
    "\n",
    "        ti = ul.find_all(\"span\",{'class':\"wineRatings_initials\"})\n",
    "        re = ul.find_all(\"span\",{'class':\"wineRatings_rating\"})\n",
    "        \n",
    "        for a, b in zip(ti, re):\n",
    "            try:\n",
    "                t = a.text\n",
    "                r = b.text\n",
    "            except:\n",
    "                t = None\n",
    "                r = None\n",
    "            title.append(t)\n",
    "            review.append(r)\n",
    "        l.append(title)\n",
    "        m.append(review)\n",
    "    return l, m\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wine description from the product page\n",
    "def prod_info(soup_prod): \n",
    "# winery description of the wine\n",
    "    try:\n",
    "        desc = soup_prod.find('div', {'class': 'viewMoreModule_text'}).getText(separator = ' ')\n",
    "    except:\n",
    "        desc=None\n",
    "    return desc\n",
    "\n",
    "# winery name\n",
    "def winery_name(soup_prod):\n",
    "    try:\n",
    "        w = soup_prod.find('h2', {'class':'pipWinery_headline'}).text\n",
    "    except:\n",
    "        w = None\n",
    "    return w\n",
    "\n",
    "# function to pull the reviewing authority initials, ratings ans the review text.\n",
    "def critical_acc(soup_prod):\n",
    "    initl = []\n",
    "    ratel = []\n",
    "    reviewl = []\n",
    "    all_rew = soup_prod.find_all('div', {'class': 'pipProfessionalReviews_list'})\n",
    "    for item in all_rew:\n",
    "        try:\n",
    "            pr_init = item.find('span', class_='wineRatings_initials').text\n",
    "            pr_rate = item.find('span', class_='wineRatings_rating').text\n",
    "            pr_review = item.find('div', {'class': 'pipSecContent_copy'}).text\n",
    "        except:\n",
    "            pr_init =  None\n",
    "            pr_rate = None\n",
    "            pr_review = None\n",
    "        initl.append(pr_init)\n",
    "        ratel.append(pr_rate)\n",
    "        reviewl.append(pr_review)\n",
    "    return initl, ratel, reviewl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requesting all items on each search page \n",
    "# def search_all_req(soup):\n",
    "#     page_items = soup.find_all('div', {\"class\": \"prodItem_wrap\"})\n",
    "    \n",
    "#     title = [prod_title(item) for item in page_items]\n",
    "#     page_link = [prodpage_link(item) for item in page_items]\n",
    "#     variety = [prod_variety(item) for item in page_items]\n",
    "#     origin = [prod_origin(item) for item in page_items]\n",
    "#     rating_count = [prod_site_rating_count(item) for item in page_items]\n",
    "#     rating_average = [prod_site_rateaverage(item) for item in page_items]\n",
    "#     img_link = [get_img(item) for item in page_items]\n",
    "    \n",
    "#     return (page_link, title, variety, origin, rating_count, rating_average, img_link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # getting all details from single product description pages\n",
    "# def single_page_req(links):\n",
    "#     p_info = []\n",
    "#     w_name= []\n",
    "#     rev_inital= []\n",
    "#     rev_rate=[] \n",
    "#     review = []\n",
    "#     for link in links:\n",
    "#         url = 'http://www.wine.com{}'.format(link)\n",
    "# #     information from each product page        \n",
    "#         res = requests.get(url)\n",
    "#         content = res.text\n",
    "#         soup_prod = BeautifulSoup(content, 'html.parser')\n",
    "#         p_info.append(prod_info(soup_prod))\n",
    "#         w_name = winery_name(soup_prod)\n",
    "#         rev_inital.append(critical_acc(soup_prod)[0])\n",
    "#         rev_rate.append(critical_acc(soup_prod)[1])\n",
    "#         review.append(critical_acc(soup_prod)[2])\n",
    "#     return p_info, w_name, rev_inital, rev_rate, review\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prof_rate = ['WS', 'RP', 'W&S', 'JH', 'CG', 'WE', 'WW', 'BH', 'JS', 'TP', 'D', 'V', 'JD']\n",
    "# 'rate_WS', 'rate_RP', 'rate_W&S', 'rate_JH', 'rate_CG', \n",
    "#                      'rate_WE', 'rate_WW', 'rate_BH', 'rate_JS', 'rate_TP', 'rate_D', 'rate_V', 'rate_JD',\n",
    "#                     'rev_WS', 'rev_RP', 'rev_W&S', 'rev_JH', 'rev_CG', 'rev_WE', 'rev_WW', 'rev_BH', 'rev_JS', \n",
    "#                      'rev_TP', 'rev_D', 'rev_V', 'rev_JD'\n",
    "# 'img_link',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlist1 = [('red-wine', 124, 3),('white-wine', 125, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wlist = [('red-wine', 124, 430),('white-wine', 125, 174), ('rose-wine', 126, 18),('champagne-and-sparkling', 123, 30)]\n",
    "\n",
    "def get_items(wtlist):\n",
    "    csv_file = open('capstone_wine_data.csv', 'w')\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['page_link','title', 'variety', 'origin', 'rating_count', 'rating_average', 'img_link',\n",
    "                        'img_name', 'description', 'winery_name', 'other_rater', 'other_ratings'])\n",
    "    \n",
    "    URL_template = 'https://www.wine.com/list/wine/{}/7155-{}/{}?showOutOfStock=false'\n",
    "\n",
    "    for item in tqdm(wtlist):\n",
    "#         print('scraping {} type wines'.format(item[0]))\n",
    "\n",
    "        for results in range(2, item[2]):\n",
    "            \n",
    "            try:\n",
    "        #  connecting to the website for each type of wine\n",
    "                URL = URL_template.format(item[0], item[1], results)\n",
    "                response = requests.get(URL)\n",
    "            # pulling the html string\n",
    "                html = response.text\n",
    "            # parsing html\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                print('Status Code: ',response.status_code)\n",
    "                \n",
    "                title = prod_title(soup)\n",
    "                page_link = prodpage_link(soup)\n",
    "                variety = prod_variety(soup)\n",
    "                origin = prod_origin(soup) \n",
    "                rating_count = prod_site_rating_count(soup)\n",
    "                rating_average = prod_site_rateaverage(soup)\n",
    "                img_link = get_img(soup)\n",
    "                other_raters, other_ratings = other_rate(soup)\n",
    "\n",
    "                for i in range(len(page_link)):  \n",
    "                    url = 'http://www.wine.com{}'.format(page_link[i])\n",
    "                    res = requests.get(url)\n",
    "                    t = res.text\n",
    "                    soup_ = BeautifulSoup(t, 'html.parser')\n",
    "                    description = prod_info(soup_)\n",
    "                    wname = winery_name(soup_)\n",
    "                    i_title = title[i].replace(\" \", '_').replace('/', '_')\n",
    "                    \n",
    "                    csv_writer.writerow([title[i], page_link[i], variety[i], \n",
    "                                 origin[i], rating_count[i], rating_average[i], \n",
    "                                 img_link[i], i_title , description, \n",
    "                                 wname, other_raters[i], other_ratings[i]])\n",
    "                    #if i%100 == 0:\n",
    "                    \n",
    "            except:\n",
    "                #response.status_code !=200\n",
    "                print('Failed')#response.status_code)\n",
    "    csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_items(wlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_(witem):\n",
    "    csv_file = open('capstone_wine_data.csv', 'w')\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['page_link','title', 'variety', 'origin', 'rating_count', 'rating_average', 'img_link',\n",
    "                        'img_name', 'description', 'winery_name', 'other_rater', 'other_ratings'])\n",
    "    \n",
    "    URL_template = 'https://www.wine.com/list/wine/{}/7155-{}/{}?showOutOfStock=false'\n",
    "\n",
    "#     for item in tqdm(wtlist):\n",
    "    print('scraping {} type wines'.format(witem[0]))\n",
    "\n",
    "    for results in range(2, witem[2]):\n",
    "            \n",
    "        try:\n",
    "        #  connecting to the website for each type of wine\n",
    "            URL = URL_template.format(witem[0], witem[1], results)\n",
    "            response = requests.get(URL)\n",
    "            # pulling the html string\n",
    "            html = response.text\n",
    "            # parsing html\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            print('Status Code: ',response.status_code)\n",
    "                \n",
    "            title = prod_title(soup)\n",
    "            page_link = prodpage_link(soup)\n",
    "            variety = prod_variety(soup)\n",
    "            origin = prod_origin(soup) \n",
    "            rating_count = prod_site_rating_count(soup)\n",
    "            rating_average = prod_site_rateaverage(soup)\n",
    "            img_link = get_img(soup)\n",
    "            other_raters, other_ratings = other_rate(soup)\n",
    "\n",
    "            for i in range(len(page_link)):  \n",
    "                url = 'http://www.wine.com{}'.format(page_link[i])\n",
    "                res = requests.get(url)\n",
    "                t = res.text\n",
    "                soup_ = BeautifulSoup(t, 'html.parser')\n",
    "                description = prod_info(soup_)\n",
    "                wname = winery_name(soup_)\n",
    "                i_title = title[i].replace(\" \", '_').replace('/', '_')\n",
    "                    \n",
    "                csv_writer.writerow([title[i], page_link[i], variety[i], \n",
    "                                 origin[i], rating_count[i], rating_average[i], \n",
    "                                 img_link[i], i_title , description, \n",
    "                                 wname, other_raters[i], other_ratings[i]])\n",
    "                    #if i%100 == 0:\n",
    "                    \n",
    "        except:\n",
    "                #response.status_code !=200\n",
    "            print('Failed')#response.status_code)\n",
    "    csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_items(results, writer):\n",
    "    writer.writerow(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_concurrent(wtlist):\n",
    "    print(\"Requesting in parallel...\\n\")\n",
    "    jobs = []\n",
    "#     for item in tqdm(wtlist):\n",
    "    thread = threading.Thread(name=wtlist, target=get_items, args=(wtlist,))\n",
    "    jobs.append(thread)\n",
    "    thread.start()\n",
    "    print(\"Waiting for threads to finish execution.\")\n",
    "#     thread.join()\n",
    "    for j in tqdm(jobs):\n",
    "        j.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "request_concurrent(wlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
